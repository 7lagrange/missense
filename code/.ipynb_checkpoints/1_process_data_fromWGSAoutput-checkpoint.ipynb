{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate files for training and prediction.\n",
    "# input is WSGA selected columns\n",
    "# remeber to change prefix to HS or HIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import numpy as np\n",
    "import sys\n",
    "import Bio.SubsMat.MatrixInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = '.HS.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FASTA_LOC = '/home/local/ARCS/hq2130/resources/hg19.fasta' # need to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def matrix_score(a_0, a_1, name_matrix=\"blosum62\"):\n",
    "    \"\"\"\n",
    "    Input: a str a_0, a str a_1, a str name_matrix\n",
    "    Output: The matrix score of a_0 and a_1 in the matrix name_matrix\n",
    "    \"\"\"\n",
    "    # Biopython also included placeholder amino acids (B. J, X, Z) in its\n",
    "    # scoring matrix.\n",
    "\n",
    "    matrix = getattr(Bio.SubsMat.MatrixInfo, name_matrix)\n",
    "\n",
    "    # Since PAM250 in Biopython is not symmetric, if (a_0, a_1) does not exist,\n",
    "    # matrix_score() will check if (a_1, a_0) exists.\n",
    "\n",
    "    if (a_0, a_1) in matrix:\n",
    "        return matrix[(a_0, a_1)]\n",
    "    elif (a_1, a_0) in matrix:\n",
    "        return matrix[(a_1, a_0)]\n",
    "    else:\n",
    "        raise KeyError(\"({}, {}) does not exist in matrix.\".format(a_0, a_1))\n",
    "        \n",
    "def add_gc_content(info):\n",
    "    chrom, pos = info['hg19_chr'], float(info['hg19_pos(1-based)'])\n",
    "    fasta_file = FASTA_LOC\n",
    "    #fasta_file = '/home/local/ARCS/hq2130/Exome_Seq/resources/hg19.fasta' # on server\n",
    "    fastafile = pysam.Fastafile(fasta_file)\n",
    "    seq = fastafile.fetch(chrom, pos, pos + 10).upper()\n",
    "    gc_count = 0\n",
    "    for dna in seq:\n",
    "        if dna in {'G', 'C'}:\n",
    "            gc_count += 1\n",
    "    gc_count = gc_count / 5.0\n",
    "    info['gc_content'] = gc_count\n",
    "    return info\n",
    "\n",
    "def add_s_het(info):\n",
    "    gene = info['genename']\n",
    "    # s_het\n",
    "    info['s_het'] = 0\n",
    "    if gene in s_het:\n",
    "        info['s_het'] = s_het[gene]\n",
    "    # s_het log, default for log transform of 0\n",
    "    info['s_het_log'] = 0 \n",
    "    if gene in s_het:\n",
    "        info['s_het_log'] = np.log(s_het[gene]+1)\n",
    "    # info['s_hat_log'] = -10 # default for log transform of 0\n",
    "    # if gene in s_hat:\n",
    "    #     info['s_hat_log'] = np.log(s_hat[gene])\n",
    "    return info\n",
    "\n",
    "def add_exac_metric(info):\n",
    "    info['pli'] = pli.get(info['genename'], '-1')\n",
    "    info['lofz'] = lofz.get(info['genename'], '0')\n",
    "    info['prec'] = prec.get(info['genename'], '0')\n",
    "    return info\n",
    "\n",
    "def add_target(info, target):\n",
    "    info['target'] = target_value\n",
    "    if target_value == 'NA' and 'cancer_target' in info:\n",
    "        info['target'] = info['cancer_target']  \n",
    "    elif target_value == 'NA' and 'category' in info:\n",
    "        if info['category'] == 'TP':\n",
    "            info['target'] = 1\n",
    "        elif info['category'] == 'TN':\n",
    "            info['target'] = 0\n",
    "    \n",
    "    return info\n",
    "\n",
    "def add_gnomad(info):\n",
    "    info['gnomad'] = 0\n",
    "    chrom, pos = info['hg19_chr'], info['hg19_pos(1-based)']\n",
    "    ref, alt = info['ref'], info['alt']\n",
    "    var_id = '_'.join([chrom, pos, ref, alt])\n",
    "    if var_id in gnomad_af:\n",
    "        info['gnomad']= gnomad_af[var_id]    \n",
    "    return info\n",
    "\n",
    "def add_secondary(info):\n",
    "    gene, aaref = info['genename'], info['aaref']\n",
    "    info['secondary_H'] = 0\n",
    "    info['secondary_C'] = 0\n",
    "    info['secondary_E'] = 0\n",
    "    if gene in secondary:\n",
    "        aapos = info['aapos'].split(';')\n",
    "        for pos in aapos:\n",
    "            pos = int(pos)\n",
    "            # AA_seq start from 0(it's a list)\n",
    "            protein_length = len(AA_seq[gene])\n",
    "            if pos < protein_length and AA_seq[gene][pos-1] == aaref:\n",
    "                if pos in secondary[gene]:\n",
    "                    if secondary[gene][pos] == 'H':\n",
    "                        info['secondary_H'] = 1\n",
    "                    elif secondary[gene][pos] == 'C':\n",
    "                        info['secondary_C'] = 1    \n",
    "                    elif secondary[gene][pos] == 'E':\n",
    "                        info['secondary_E'] = 1\n",
    "    return info\n",
    "                                    \n",
    "def add_BioPlex(info):\n",
    "    ''' some feather related to protein? added all pint \n",
    "        http://bioplex.hms.harvard.edu/downloadInteractions.php\n",
    "    '''\n",
    "    gene = info['genename']\n",
    "    info['BioPlex'] = -1\n",
    "    if gene in BioPlex:\n",
    "        info['BioPlex'] = BioPlex[gene]\n",
    "    return info\n",
    "        \n",
    "def choose_HS(info):\n",
    "    include_variants = False  \n",
    "    if float(info['pli']) < 0.5 and float(info['pli']) >= 0: # HS genes\n",
    "        include_variants = True  \n",
    "    return include_variants\n",
    "\n",
    "def choose_HIS(info):\n",
    "    include_variants = False  \n",
    "    if float(info['pli']) >= 0.5: # HIS genes\n",
    "        include_variants = True  \n",
    "    return include_variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=True):\n",
    "    \"\"\" function that selected colums from wgsa, add some other feathers \n",
    "        set . into 0\n",
    "    \"\"\"\n",
    "    with open(fin, 'rU') as f:\n",
    "        positive, negative = 0, 0\n",
    "        \n",
    "        r = csv.reader(f)\n",
    "        head = r.next()\n",
    "        feat_all = wgsa_feat + add_feat + extra_feat\n",
    "        feat = []\n",
    "        for f in order_feat:\n",
    "            if f in feat_all:\n",
    "                feat.append(f)\n",
    "        for f in feat_all:\n",
    "            if f not in feat:\n",
    "                feat.append(f)\n",
    "        if write_head:\n",
    "            w.writerow(feat)\n",
    "\n",
    "        for line in r:\n",
    "            info = dict(zip(head, line))\n",
    "            aaref, aaalt, aapos = info['aaref'], info['aaalt'], info['aapos']\n",
    "            \n",
    "            var_id = '_'.join([info['hg19_chr'], info['hg19_pos(1-based)'], info['ref'], info['alt']])\n",
    "            if var_id in exclude_var: continue\n",
    "            \n",
    "            # no aaalt \n",
    "            if aaref is not \"U\" and aaalt is not \".\":\n",
    "                # reformat wsga feat, missing value filled with 0, will -1 be better?\n",
    "                for c in wgsa_feat:\n",
    "                    if info[c] == '.':\n",
    "                        info[c] = -1\n",
    "                    else:\n",
    "                        info[c] = float(info[c])\n",
    "                # set some default value for extra_feat\n",
    "                for c in extra_feat:\n",
    "                    info[c] = info.get(c, 'NA')\n",
    "                \n",
    "                info['genename'] = info['genename']\n",
    "                info['blosum62'] = matrix_score(aaref, aaalt, 'blosum62')\n",
    "                info['pam250'] = matrix_score(aaref, aaalt, 'pam250')\n",
    "                \n",
    "                \n",
    "               \n",
    "                \n",
    "                # update SUMO/phospho scores\n",
    "                info['phospho_score'] = 0\n",
    "                info['phospho_cutoff'] = 0\n",
    "                info['phospho_diff'] = 0\n",
    "                gene = info['genename']\n",
    "                if gene in phosphorylation:\n",
    "                    aapos = info['aapos'].split(';')\n",
    "                    for pos in aapos:\n",
    "                        pos = int(pos)\n",
    "                        # pos is 1 based\n",
    "                        if pos in phosphorylation[gene]:\n",
    "                            if phosphorylation[gene][pos]['AA'] == aaref:\n",
    "                                info['phospho_score'] = phosphorylation[gene][pos]['Score']\n",
    "                                info['phospho_cutoff'] = phosphorylation[gene][pos]['Cutoff']\n",
    "                                info['phospho_diff'] = phosphorylation[gene][pos]['diff']\n",
    "                                break\n",
    "                                \n",
    "                info['SUMO_score'] = 0\n",
    "                info['SUMO_cutoff'] = 0\n",
    "                info['SUMO_diff'] = 0\n",
    "                if gene in SUMO:\n",
    "                    aapos = info['aapos'].split(';')\n",
    "                    for pos in aapos:\n",
    "                        pos = int(pos)\n",
    "                        # pos is 1 based\n",
    "                        if pos in SUMO[gene]:\n",
    "                            if SUMO[gene][pos]['AA'] == aaref:\n",
    "                                info['SUMO_score'] = SUMO[gene][pos]['Score']\n",
    "                                info['SUMO_cutoff'] = SUMO[gene][pos]['Cutoff']\n",
    "                                info['SUMO_diff'] = SUMO[gene][pos]['diff']\n",
    "                                break  \n",
    "                                \n",
    "                # add inteface flag\n",
    "                info['interface'] = 0\n",
    "                if gene in interface:\n",
    "                    aapos = info['aapos'].split(';')\n",
    "                    for pos in aapos:\n",
    "                        pos = int(pos)\n",
    "                        # AA_seq start from 0\n",
    "                        protein_length = len(AA_seq[gene])\n",
    "                        if pos < protein_length and AA_seq[gene][pos-1] == aaref:\n",
    "                            if pos in interface[gene]:\n",
    "                                info['interface'] = 1\n",
    "                                \n",
    "                # add ASA score Accessible Surface Areas\n",
    "                info['ASA'] = 0\n",
    "                if gene in ASA:\n",
    "                    aapos = info['aapos'].split(';')\n",
    "                    for pos in aapos:\n",
    "                        pos = int(pos)\n",
    "                        # AA_seq start from 0\n",
    "                        protein_length = len(AA_seq[gene])\n",
    "                        if pos < protein_length and AA_seq[gene][pos-1] == aaref:\n",
    "                            if pos in ASA[gene]:\n",
    "                                info['ASA'] = ASA[gene][pos]\n",
    "                \n",
    "\n",
    "                                    \n",
    "                info['ubiquitination'] = 0\n",
    "                if gene in ubiquitination:\n",
    "                    aapos = info['aapos'].split(';')\n",
    "                    for pos in aapos:\n",
    "                        pos = int(pos)\n",
    "                        # AA_seq start from 0\n",
    "                        protein_length = len(AA_seq[gene])\n",
    "                        if pos < protein_length and AA_seq[gene][pos-1] == aaref:\n",
    "                            if pos in ubiquitination[gene]:\n",
    "                                info['ubiquitination'] = ubiquitination[gene][pos]\n",
    "                \n",
    "                # gene specific feathers\n",
    "                info['complex_CORUM'] = 0\n",
    "                if gene in complex_CORUM:\n",
    "                    info['complex_CORUM'] = 1\n",
    "                \n",
    "                info['preppi_counts'] = 0\n",
    "                if gene in preppi:\n",
    "                    info['preppi_counts'] = preppi[gene]\n",
    "                    \n",
    "                info = add_secondary(info)\n",
    "                info = add_exac_metric(info)\n",
    "                info = add_gc_content(info)\n",
    "                info = add_s_het(info)\n",
    "                info = add_BioPlex(info)\n",
    "                \n",
    "                info = add_target(info, target_value)\n",
    "                info = add_gnomad(info)\n",
    "               \n",
    "                # choose variants in HIS or HS\n",
    "                if prefix == '.HS.':\n",
    "                    include_variants = choose_HS(info)\n",
    "                else:\n",
    "                    include_variants = choose_HIS(info)\n",
    "                if include_variants:\n",
    "                    if info['target'] == 1:\n",
    "                        positive += 1\n",
    "                    if info['target'] == 0:\n",
    "                        negative += 1\n",
    "                    w.writerow([info[c] for c in feat])\n",
    "                    \n",
    "    print '{} pos, {} neg'.format(positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variants excluded for training\n",
    "exclude_var = set()\n",
    "with open('../data/excluded_variants_gwas.txt') as f:\n",
    "    for line in f:\n",
    "        exclude_var.add(line.strip())  \n",
    "        \n",
    "with open('../data/input_data.exclude.txt') as f:\n",
    "    for line in f:\n",
    "        exclude_var.add(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load protein related annotations\n",
    "SUMO = np.load('../data/protein/SUMO.npy').item()\n",
    "phosphorylation = np.load('../data/protein/phosphorylation.npy').item()\n",
    "AA_seq = np.load('../data/protein/AA_seq.npy').item()\n",
    "interface = np.load('../data/protein/interface.npy').item()\n",
    "ASA = np.load('../data/protein/ASA.npy').item()\n",
    "preppi = np.load('../data/protein/preppi.npy').item()\n",
    "secondary = np.load('../data/protein/secondary.npy').item()\n",
    "ubiquitination = np.load('../data/protein/ubiquitination.npy').item()\n",
    "BioPlex = np.load('../data/protein/BioPlex.npy').item()\n",
    "\n",
    "s_het = np.load('../data/gene/s_het.npy').item()\n",
    "prec = np.load('../data/gene/prec.npy').item()\n",
    "pli = np.load('../data/gene/pli.npy').item()\n",
    "lofz = np.load('../data/gene/lofz.npy').item()\n",
    "\n",
    "gnomad_af = np.load('../data/training/gnomad_af.npy').item()\n",
    "\n",
    "\n",
    "complex_CORUM = set()\n",
    "with open('../data/protein/protein_complex_CORUM.txt') as f:\n",
    "    for line in f:\n",
    "        lst = line.strip().split('\\t')\n",
    "        complex_CORUM = complex_CORUM | set(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature order from correlation cluster\n",
    "order_feat = [u'MutationAssessor_score_rankscore', u'VEST3_rankscore', u'Polyphen2_HDIV_rankscore',\n",
    " u'Polyphen2_HVAR_rankscore', u'SIFT_converted_rankscore', u'PROVEAN_converted_rankscore',\n",
    " u'MetaSVM_rankscore',u'MetaLR_rankscore', u'FATHMM_converted_rankscore', u'M-CAP_rankscore',\n",
    " u'GenoCanyon_score_rankscore', u'LRT_converted_rankscore', u'Eigen-PC-raw_rankscore',\n",
    " u'Eigen-phred', u'Eigen-PC-phred', u'DANN_rankscore', u'CADD_phred', u'CADD_raw_rankscore',\n",
    " u'phyloP20way_mammalian_rankscore', u'GERP++_RS_rankscore', u'SiPhy_29way_logOdds_rankscore',\n",
    " u'phastCons100way_vertebrate_rankscore', u'fathmm-MKL_coding_rankscore', u'phyloP100way_vertebrate_rankscore',\n",
    " u'MutationTaster_converted_rankscore', u'phastCons20way_mammalian_rankscore', u'GM12878_fitCons_score_rankscore',\n",
    " u'HUVEC_fitCons_score_rankscore', u'integrated_fitCons_score_rankscore',u'H1-hESC_fitCons_score_rankscore', \n",
    " u'blosum62', u'pam250', u'SUMO_diff', u'SUMO_score', u'SUMO_cutoff', u'phospho_cutoff', u'phospho_score',\n",
    " u'phospho_diff', u'lofz', u'prec', u'pli',\n",
    " u's_het', u's_het_log', u'secondary_E', u'secondary_H', u'complex_CORUM', u'preppi_counts',\n",
    " u'1000Gp3_AF', u'ExAC_AF', 'gnomad', u'ASA', u'secondary_C', u'gc_content', u'interface', u'ubiquitination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add feathers from WGSA and other inputs, some of them need to be excluded in future training\n",
    "rank_score_cols = ['SIFT_converted_rankscore', 'Polyphen2_HDIV_rankscore', 'Polyphen2_HVAR_rankscore', \n",
    " 'LRT_converted_rankscore', 'MutationTaster_converted_rankscore', 'MutationAssessor_score_rankscore', \n",
    " 'FATHMM_converted_rankscore', 'PROVEAN_converted_rankscore', 'VEST3_rankscore', \n",
    " 'MetaSVM_rankscore', 'MetaLR_rankscore', 'M-CAP_rankscore', \n",
    " 'CADD_raw_rankscore', 'DANN_rankscore', 'fathmm-MKL_coding_rankscore', \n",
    " 'Eigen-PC-raw_rankscore', 'GenoCanyon_score_rankscore', 'integrated_fitCons_score_rankscore', \n",
    " 'GM12878_fitCons_score_rankscore', 'H1-hESC_fitCons_score_rankscore', \n",
    " 'HUVEC_fitCons_score_rankscore', 'GERP++_RS_rankscore', \n",
    " 'phyloP100way_vertebrate_rankscore', 'phyloP20way_mammalian_rankscore', \n",
    " 'phastCons100way_vertebrate_rankscore', 'phastCons20way_mammalian_rankscore', \n",
    " 'SiPhy_29way_logOdds_rankscore']\n",
    "\n",
    "wgsa_feat = ['1000Gp3_AF', 'ExAC_AF', 'CADD_phred', 'Eigen-phred', 'Eigen-PC-phred']\n",
    "wgsa_feat = wgsa_feat + rank_score_cols\n",
    "\n",
    "add_feat =  ['blosum62', 'pam250', 'SUMO_score', 'SUMO_cutoff', 'SUMO_diff',\n",
    "             'phospho_score', 'phospho_cutoff','phospho_diff', 'interface',\n",
    "             'ASA', 'pli', 'lofz', 'complex_CORUM', 'preppi_counts',\n",
    "             'secondary_H', 'secondary_C', 'secondary_E', 'ubiquitination',\n",
    "             's_het', 'prec', 's_het_log',   'gc_content', 'gnomad', 'BioPlex',\n",
    "             'target']\n",
    "\n",
    "# feathers used for future info\n",
    "extra_feat = ['hg19_chr', 'hg19_pos(1-based)', \n",
    "              'ref', 'alt', 'category', 'source','INFO', 'disease', 'genename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12986 pos, 0 neg\n",
      "0 pos, 8497 neg\n",
      "5656 pos, 2704 neg\n",
      "0 pos, 7723 neg\n"
     ]
    }
   ],
   "source": [
    "outname = '../data/input_data' + prefix + 'csv'\n",
    "\n",
    "\n",
    "with open(outname, 'w') as fw:\n",
    "    w = csv.writer(fw)\n",
    "\n",
    "    # HGMD positive training\n",
    "    fin = '../data/training/HGMD_DM_missense_anno.rare.csv' \n",
    "    target_value = 1\n",
    "    sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=True)\n",
    "\n",
    "    # Discover negative data\n",
    "    fin = '../data/training/DiscovEHR_rare_missense_30000.csv' \n",
    "    target_value = 0\n",
    "    sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=False)\n",
    "    \n",
    "    # metaSVM training \n",
    "    fin = '../data/training/metaSVM_train.anno.rare.csv' \n",
    "    target_value = 'NA'\n",
    "    sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=False)\n",
    "    \n",
    "    # CADD negative data\n",
    "    fin = '../data/training/CADD_neg_train.anno.rare.csv' \n",
    "    target_value = 0\n",
    "    sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=False)\n",
    "    \n",
    "#     # CADD simulation pos training\n",
    "#     # performance is worse if add cadd pos training dataset\n",
    "#     fin = '../data/training/CADD_simu_pos.anno.rare.csv' \n",
    "#     target_value = 1\n",
    "#     sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "file `/home/local/ARCS/hq2130/resources/hg19.fasta` not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e35588ac28c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtarget_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'NA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0msel_add_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwgsa_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_head\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-05ef69c18e2b>\u001b[0m in \u001b[0;36msel_add_feather\u001b[0;34m(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_secondary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_exac_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_gc_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_s_het\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_BioPlex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a740621b453d>\u001b[0m in \u001b[0;36madd_gc_content\u001b[0;34m(info)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mfasta_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFASTA_LOC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#fasta_file = '/home/local/ARCS/hq2130/Exome_Seq/resources/hg19.fasta' # on server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mfastafile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpysam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastafile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasta_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfastafile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchrom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mgc_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpysam/libcfaidx.pyx\u001b[0m in \u001b[0;36mpysam.libcfaidx.FastaFile.__cinit__ (pysam/libcfaidx.c:2166)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpysam/libcfaidx.pyx\u001b[0m in \u001b[0;36mpysam.libcfaidx.FastaFile._open (pysam/libcfaidx.c:2675)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: file `/home/local/ARCS/hq2130/resources/hg19.fasta` not found"
     ]
    }
   ],
   "source": [
    "# metaSVM testing\n",
    "fins = ['../data/metaSVM/metaSVM_train.anno.rare.csv', '../data/metaSVM/metaSVM_test1.anno.rare.csv', \n",
    "       '../data/metaSVM/metaSVM_test2.anno.rare.csv', '../data/metaSVM/metaSVM_test3.anno.rare.csv', \n",
    "       '../data/metaSVM/metaSVM_addtest1.anno.rare.csv', '../data/metaSVM/metaSVM_addtest2.anno.rare.csv',\n",
    "       '../data/cancer_hotspots/cancer.csv','../data/cancer_hotspots/cancer_sel.csv',\n",
    "       '../data/gene_test/MCAP_test.anno.rare.csv']\n",
    "\n",
    "fouts = []\n",
    "for f in fins:\n",
    "    fouts.append(f.split('.csv')[0] + prefix + 'reformat.csv')\n",
    "for fin, fout in zip(fins, fouts):\n",
    "    with open(fout, 'w') as fw:\n",
    "        w = csv.writer(fw)\n",
    "        target_value = 'NA'\n",
    "        sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 pos, 227 neg\n",
      "0 pos, 425 neg\n",
      "0 pos, 454 neg\n"
     ]
    }
   ],
   "source": [
    "fins = ['../data/case_control/control_900.anno.rare.csv',\n",
    "        '../data/case_control/control_1911.anno.rare.csv',\n",
    "        '../data/case_control/ssc_yale.anno.rare.csv']\n",
    "\n",
    "fouts = []\n",
    "for f in fins:\n",
    "    fouts.append(f.split('.csv')[0] + prefix + 'reformat.csv')\n",
    "\n",
    "for fin, fout in zip(fins, fouts):\n",
    "    with open(fout, 'w') as fw:\n",
    "        w = csv.writer(fw)\n",
    "        target_value = 0\n",
    "        sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2838 pos, 0 neg\n",
      "2037 pos, 0 neg\n",
      "817 pos, 0 neg\n"
     ]
    }
   ],
   "source": [
    "fins = ['../data/case_control/case.anno.rare.csv', \n",
    "        '../data/case_control/DDD_new_0.2.anno.rare.csv',\n",
    "        '../data/case_control/chd_yale.anno.rare.csv']\n",
    "\n",
    "fouts = []\n",
    "for f in fins:\n",
    "    fouts.append(f.split('.csv')[0] + prefix +'reformat.csv')\n",
    "\n",
    "for fin, fout in zip(fins, fouts):\n",
    "    with open(fout, 'w') as fw:\n",
    "        w = csv.writer(fw)\n",
    "        target_value = 1\n",
    "        sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process all missense and all cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 pos, 0 neg\n"
     ]
    }
   ],
   "source": [
    "# all cancer hostspot and other files\n",
    "fins = ['/data/hq2130/large_files/cancer_all.csv']\n",
    "\n",
    "fouts = []\n",
    "for f in fins:\n",
    "    fouts.append(f.split('.csv')[0] + prefix + 'reformat.csv')\n",
    "for fin, fout in zip(fins, fouts):\n",
    "    with open(fout, 'w') as fw:\n",
    "        w = csv.writer(fw)\n",
    "        target_value = 'NA'\n",
    "        sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 pos, 0 neg\n"
     ]
    }
   ],
   "source": [
    "# all cancer hostspot and other files\n",
    "fins = ['/data/hq2130/large_files/rare_missense_id.anno.rare.csv']\n",
    "\n",
    "fouts = []\n",
    "for f in fins:\n",
    "    fouts.append(f.split('.csv')[0] + prefix + 'reformat.csv')\n",
    "for fin, fout in zip(fins, fouts):\n",
    "    with open(fout, 'w') as fw:\n",
    "        w = csv.writer(fw)\n",
    "        target_value = 'NA'\n",
    "        sel_add_feather(fin, w, wgsa_feat, add_feat, extra_feat, target_value, write_head=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_section_display": "block",
   "toc_threshold": 6,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
